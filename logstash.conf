input {
    file {
        #https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html
        #default is TAIL which assumes more data will come into the file.
        #change to mode => "read" if the file is a compelte file.  by default, the file will be removed once reading is complete -- backup your files if you need them.
        mode => "tail"
        path => "/usr/share/logstash/ingest_data/*"
    }

    syslog {
        host => "0.0.0.0"
        port => 5141
        type => "syslog_combined" 
    }

    beats {
        port => 5044
        type => "beats_logs"
    }
}


filter {
}


output {
    elasticsearch {
        #index => "logstash-%{+YYYY.MM.dd}" # Default index name
        hosts=> "${ELASTIC_HOSTS}"
        user=> "${ELASTIC_USER}"
        password=> "${ELASTIC_PASSWORD}"
        #cacert=> "certs/ca/ca.crt"
        ssl_enabled => true
        ssl_certificate_authorities => ["/usr/share/logstash/certs/ca/ca.crt"]

        data_stream => true
        data_stream_type => "logs"
        data_stream_dataset => "pfsense.log"     # choose the dataset you want
        data_stream_namespace => "default"       # choose the namespace you want 

        # Use a specific index and pipeline for pfSense logs
        pipeline => "logs-pfsense.log-1.23.1" 
    }

    # Debug Output: Print events to console
    # stdout { codec => rubydebug }
}